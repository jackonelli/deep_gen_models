"Unet(\n  (init_conv): Conv2d(1, 28, kernel_size=(1, 1), stride=(1, 1))\n  (final_res_block):\
  \ ResnetBlock(\n    (mlp): Sequential(\n      (0): SiLU()\n      (1): Linear(in_features=112,\
  \ out_features=56, bias=True)\n    )\n    (block1): Block(\n      (proj): WeightStandardizedConv2d(56,\
  \ 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (norm): GroupNorm(4,\
  \ 28, eps=1e-05, affine=True)\n      (act): SiLU()\n    )\n    (block2): Block(\n\
  \      (proj): WeightStandardizedConv2d(28, 28, kernel_size=(3, 3), stride=(1, 1),\
  \ padding=(1, 1))\n      (norm): GroupNorm(4, 28, eps=1e-05, affine=True)\n    \
  \  (act): SiLU()\n    )\n    (res_conv): Conv2d(56, 28, kernel_size=(1, 1), stride=(1,\
  \ 1))\n  )\n  (final_conv): Conv2d(28, 1, kernel_size=(1, 1), stride=(1, 1))\n \
  \ (downs): ModuleList(\n    (0): ModuleList(\n      (0-1): 2 x ResnetBlock(\n  \
  \      (mlp): Sequential(\n          (0): SiLU()\n          (1): Linear(in_features=112,\
  \ out_features=56, bias=True)\n        )\n        (block1): Block(\n          (proj):\
  \ WeightStandardizedConv2d(28, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1,\
  \ 1))\n          (norm): GroupNorm(4, 28, eps=1e-05, affine=True)\n          (act):\
  \ SiLU()\n        )\n        (block2): Block(\n          (proj): WeightStandardizedConv2d(28,\
  \ 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (norm): GroupNorm(4,\
  \ 28, eps=1e-05, affine=True)\n          (act): SiLU()\n        )\n        (res_conv):\
  \ Identity()\n      )\n      (2): Residual(\n        (fn): PreNorm(\n          (fn):\
  \ LinearAttention(\n            (to_qkv): Conv2d(28, 384, kernel_size=(1, 1), stride=(1,\
  \ 1), bias=False)\n            (to_out): Sequential(\n              (0): Conv2d(128,\
  \ 28, kernel_size=(1, 1), stride=(1, 1))\n              (1): GroupNorm(1, 28, eps=1e-05,\
  \ affine=True)\n            )\n          )\n          (norm): GroupNorm(1, 28, eps=1e-05,\
  \ affine=True)\n        )\n      )\n      (3): Sequential(\n        (0): Rearrange('b\
  \ c (h p1) (w p2) -> b (c p1 p2) h w', p1=2, p2=2)\n        (1): Conv2d(112, 28,\
  \ kernel_size=(1, 1), stride=(1, 1))\n      )\n    )\n    (1): ModuleList(\n   \
  \   (0-1): 2 x ResnetBlock(\n        (mlp): Sequential(\n          (0): SiLU()\n\
  \          (1): Linear(in_features=112, out_features=56, bias=True)\n        )\n\
  \        (block1): Block(\n          (proj): WeightStandardizedConv2d(28, 28, kernel_size=(3,\
  \ 3), stride=(1, 1), padding=(1, 1))\n          (norm): GroupNorm(4, 28, eps=1e-05,\
  \ affine=True)\n          (act): SiLU()\n        )\n        (block2): Block(\n \
  \         (proj): WeightStandardizedConv2d(28, 28, kernel_size=(3, 3), stride=(1,\
  \ 1), padding=(1, 1))\n          (norm): GroupNorm(4, 28, eps=1e-05, affine=True)\n\
  \          (act): SiLU()\n        )\n        (res_conv): Identity()\n      )\n \
  \     (2): Residual(\n        (fn): PreNorm(\n          (fn): LinearAttention(\n\
  \            (to_qkv): Conv2d(28, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n\
  \            (to_out): Sequential(\n              (0): Conv2d(128, 28, kernel_size=(1,\
  \ 1), stride=(1, 1))\n              (1): GroupNorm(1, 28, eps=1e-05, affine=True)\n\
  \            )\n          )\n          (norm): GroupNorm(1, 28, eps=1e-05, affine=True)\n\
  \        )\n      )\n      (3): Sequential(\n        (0): Rearrange('b c (h p1)\
  \ (w p2) -> b (c p1 p2) h w', p1=2, p2=2)\n        (1): Conv2d(112, 56, kernel_size=(1,\
  \ 1), stride=(1, 1))\n      )\n    )\n    (2): ModuleList(\n      (0-1): 2 x ResnetBlock(\n\
  \        (mlp): Sequential(\n          (0): SiLU()\n          (1): Linear(in_features=112,\
  \ out_features=112, bias=True)\n        )\n        (block1): Block(\n          (proj):\
  \ WeightStandardizedConv2d(56, 56, kernel_size=(3, 3), stride=(1, 1), padding=(1,\
  \ 1))\n          (norm): GroupNorm(4, 56, eps=1e-05, affine=True)\n          (act):\
  \ SiLU()\n        )\n        (block2): Block(\n          (proj): WeightStandardizedConv2d(56,\
  \ 56, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (norm): GroupNorm(4,\
  \ 56, eps=1e-05, affine=True)\n          (act): SiLU()\n        )\n        (res_conv):\
  \ Identity()\n      )\n      (2): Residual(\n        (fn): PreNorm(\n          (fn):\
  \ LinearAttention(\n            (to_qkv): Conv2d(56, 384, kernel_size=(1, 1), stride=(1,\
  \ 1), bias=False)\n            (to_out): Sequential(\n              (0): Conv2d(128,\
  \ 56, kernel_size=(1, 1), stride=(1, 1))\n              (1): GroupNorm(1, 56, eps=1e-05,\
  \ affine=True)\n            )\n          )\n          (norm): GroupNorm(1, 56, eps=1e-05,\
  \ affine=True)\n        )\n      )\n      (3): Conv2d(56, 112, kernel_size=(3, 3),\
  \ stride=(1, 1), padding=(1, 1))\n    )\n  )\n  (ups): ModuleList(\n    (0): ModuleList(\n\
  \      (0-1): 2 x ResnetBlock(\n        (mlp): Sequential(\n          (0): SiLU()\n\
  \          (1): Linear(in_features=112, out_features=224, bias=True)\n        )\n\
  \        (block1): Block(\n          (proj): WeightStandardizedConv2d(168, 112,\
  \ kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (norm): GroupNorm(4,\
  \ 112, eps=1e-05, affine=True)\n          (act): SiLU()\n        )\n        (block2):\
  \ Block(\n          (proj): WeightStandardizedConv2d(112, 112, kernel_size=(3, 3),\
  \ stride=(1, 1), padding=(1, 1))\n          (norm): GroupNorm(4, 112, eps=1e-05,\
  \ affine=True)\n          (act): SiLU()\n        )\n        (res_conv): Conv2d(168,\
  \ 112, kernel_size=(1, 1), stride=(1, 1))\n      )\n      (2): Residual(\n     \
  \   (fn): PreNorm(\n          (fn): LinearAttention(\n            (to_qkv): Conv2d(112,\
  \ 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (to_out): Sequential(\n\
  \              (0): Conv2d(128, 112, kernel_size=(1, 1), stride=(1, 1))\n      \
  \        (1): GroupNorm(1, 112, eps=1e-05, affine=True)\n            )\n       \
  \   )\n          (norm): GroupNorm(1, 112, eps=1e-05, affine=True)\n        )\n\
  \      )\n      (3): Sequential(\n        (0): Upsample(scale_factor=2.0, mode='nearest')\n\
  \        (1): Conv2d(112, 56, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n\
  \      )\n    )\n    (1): ModuleList(\n      (0-1): 2 x ResnetBlock(\n        (mlp):\
  \ Sequential(\n          (0): SiLU()\n          (1): Linear(in_features=112, out_features=112,\
  \ bias=True)\n        )\n        (block1): Block(\n          (proj): WeightStandardizedConv2d(84,\
  \ 56, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (norm): GroupNorm(4,\
  \ 56, eps=1e-05, affine=True)\n          (act): SiLU()\n        )\n        (block2):\
  \ Block(\n          (proj): WeightStandardizedConv2d(56, 56, kernel_size=(3, 3),\
  \ stride=(1, 1), padding=(1, 1))\n          (norm): GroupNorm(4, 56, eps=1e-05,\
  \ affine=True)\n          (act): SiLU()\n        )\n        (res_conv): Conv2d(84,\
  \ 56, kernel_size=(1, 1), stride=(1, 1))\n      )\n      (2): Residual(\n      \
  \  (fn): PreNorm(\n          (fn): LinearAttention(\n            (to_qkv): Conv2d(56,\
  \ 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (to_out): Sequential(\n\
  \              (0): Conv2d(128, 56, kernel_size=(1, 1), stride=(1, 1))\n       \
  \       (1): GroupNorm(1, 56, eps=1e-05, affine=True)\n            )\n         \
  \ )\n          (norm): GroupNorm(1, 56, eps=1e-05, affine=True)\n        )\n   \
  \   )\n      (3): Sequential(\n        (0): Upsample(scale_factor=2.0, mode='nearest')\n\
  \        (1): Conv2d(56, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n\
  \      )\n    )\n    (2): ModuleList(\n      (0-1): 2 x ResnetBlock(\n        (mlp):\
  \ Sequential(\n          (0): SiLU()\n          (1): Linear(in_features=112, out_features=56,\
  \ bias=True)\n        )\n        (block1): Block(\n          (proj): WeightStandardizedConv2d(56,\
  \ 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (norm): GroupNorm(4,\
  \ 28, eps=1e-05, affine=True)\n          (act): SiLU()\n        )\n        (block2):\
  \ Block(\n          (proj): WeightStandardizedConv2d(28, 28, kernel_size=(3, 3),\
  \ stride=(1, 1), padding=(1, 1))\n          (norm): GroupNorm(4, 28, eps=1e-05,\
  \ affine=True)\n          (act): SiLU()\n        )\n        (res_conv): Conv2d(56,\
  \ 28, kernel_size=(1, 1), stride=(1, 1))\n      )\n      (2): Residual(\n      \
  \  (fn): PreNorm(\n          (fn): LinearAttention(\n            (to_qkv): Conv2d(28,\
  \ 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (to_out): Sequential(\n\
  \              (0): Conv2d(128, 28, kernel_size=(1, 1), stride=(1, 1))\n       \
  \       (1): GroupNorm(1, 28, eps=1e-05, affine=True)\n            )\n         \
  \ )\n          (norm): GroupNorm(1, 28, eps=1e-05, affine=True)\n        )\n   \
  \   )\n      (3): Conv2d(28, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1,\
  \ 1))\n    )\n  )\n  (time_mlp): Sequential(\n    (0): SinusoidalPositionEmbeddings()\n\
  \    (1): Linear(in_features=112, out_features=112, bias=True)\n    (2): GELU(approximate='none')\n\
  \    (3): Linear(in_features=112, out_features=112, bias=True)\n  )\n  (middle):\
  \ ModuleList(\n    (0): ResnetBlock(\n      (mlp): Sequential(\n        (0): SiLU()\n\
  \        (1): Linear(in_features=112, out_features=224, bias=True)\n      )\n  \
  \    (block1): Block(\n        (proj): WeightStandardizedConv2d(112, 112, kernel_size=(3,\
  \ 3), stride=(1, 1), padding=(1, 1))\n        (norm): GroupNorm(4, 112, eps=1e-05,\
  \ affine=True)\n        (act): SiLU()\n      )\n      (block2): Block(\n       \
  \ (proj): WeightStandardizedConv2d(112, 112, kernel_size=(3, 3), stride=(1, 1),\
  \ padding=(1, 1))\n        (norm): GroupNorm(4, 112, eps=1e-05, affine=True)\n \
  \       (act): SiLU()\n      )\n      (res_conv): Identity()\n    )\n    (1): Residual(\n\
  \      (fn): PreNorm(\n        (fn): Attention(\n          (to_qkv): Conv2d(112,\
  \ 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (to_out): Conv2d(128,\
  \ 112, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (norm): GroupNorm(1,\
  \ 112, eps=1e-05, affine=True)\n      )\n    )\n    (2): ResnetBlock(\n      (mlp):\
  \ Sequential(\n        (0): SiLU()\n        (1): Linear(in_features=112, out_features=224,\
  \ bias=True)\n      )\n      (block1): Block(\n        (proj): WeightStandardizedConv2d(112,\
  \ 112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (norm): GroupNorm(4,\
  \ 112, eps=1e-05, affine=True)\n        (act): SiLU()\n      )\n      (block2):\
  \ Block(\n        (proj): WeightStandardizedConv2d(112, 112, kernel_size=(3, 3),\
  \ stride=(1, 1), padding=(1, 1))\n        (norm): GroupNorm(4, 112, eps=1e-05, affine=True)\n\
  \        (act): SiLU()\n      )\n      (res_conv): Identity()\n    )\n  )\n)"
