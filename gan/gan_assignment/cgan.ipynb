{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac411205",
   "metadata": {},
   "source": [
    "# GANs\n",
    "In this assignment, you will first implement the original GAN and the Wasserstein GAN (WGAN) on a toy problem to see how the relatively small changes can lead to big changes during training. Then, you will train a Conditional GAN (cGAN) on the same dataset as in the previos assignment, namely MNIST.\n",
    "\n",
    "## Setup\n",
    "To facilitate the assignment, we use the same enviorments as in the previous assignments. If you installed the environment in the previous assignment, you can simply do `conda activate vae`. Otherwise, run the following:\n",
    "```\n",
    "conda env create -f environments/environment-gpu.yml\n",
    "conda activate vae\n",
    "```\n",
    "\n",
    "or\n",
    "\n",
    "```\n",
    "conda env create -f environments/environment-cpu-only.yml\n",
    "conda activate vae\n",
    "```\n",
    "\n",
    "## How to complete this assignment\n",
    "\n",
    "Throughout this assignment there are several places where you will need to fill in code. These are marked with `YOUR CODE HERE` comments. Further, there are several places where you will need to answer questions. These are marked with `YOUR ANSWER HERE` comments. You should replace the `YOUR CODE HERE` and `YOUR ANSWER HERE` comments with your code and answers. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4580d486",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6692b3f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "12f2ee7a6bc485576072c4e67128f59b",
     "grade": false,
     "grade_id": "cell-ed8e35d510e9d0f7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(1337)\n",
    "np.random.seed(1337)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51ec422",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "98c10d851c366f01bb9b0f981bda3c8d",
     "grade": false,
     "grade_id": "cell-c0c6302798d90653",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Part 2: Conditional GAN\n",
    "When using GANs, it could be very useful to generate a particular type of images from the full data distribution. In this part, we will implement a conditional GAN (cGAN) that can generate images of specific hand-written digits using the MNIST dataset.\n",
    "\n",
    "Initially, we want you to implement the conditional generator. It should be a MLP with the follwing architecture:\n",
    "- An input node that takes the concatenated noise vector and the embedded label as input.\n",
    "- A LeakyReLU layer with a slope of 0.2.\n",
    "- 3 fully connected layers with 256, 512 and 1024 nodes respectively, which all should be follwed by a BatchNorm and a LeakyReLU activation.\n",
    "- An output layer with im_height * im_width * im_channels nodes and a Tanh activation.\n",
    "\n",
    "The forward pass should: \n",
    "- Embed the label\n",
    "- Concatenate the noise vector and the embedded label.\n",
    "- Pass the concatenated vector through the MLP.\n",
    "- Reshape the output to the correct image size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3652e4",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6ef2b008fe36c4269d305fc810cab2a0",
     "grade": true,
     "grade_id": "cell-2229d11729b56c83",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class ConditionalGenerator(nn.Module):\n",
    "    def __init__(self, n_classes: int, n_channels: int, img_size: int, latent_dim: int):\n",
    "        super(ConditionalGenerator, self).__init__()\n",
    "        self.n_classes = n_classes\n",
    "        self.n_channels = n_channels\n",
    "        self.img_size = img_size\n",
    "        self.latent_dim = latent_dim\n",
    "        self.img_shape = (self.n_channels, self.img_size, self.img_size)\n",
    "        self.label_embedding = nn.Embedding(self.n_classes, self.n_classes)\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def forward(self, noise: torch.Tensor, labels: torch.Tensor):\n",
    "        \"\"\"Generates an image given a noise vector and a label.\n",
    "\n",
    "        Args:\n",
    "            noise (torch.Tensor): A noise vector of shape (batch_size, latent_dim)\n",
    "            labels (torch.Tensor): A label vector of shape (batch_size)\n",
    "        Returns:\n",
    "            torch.Tensor: A generated image of shape (batch_size, n_channels, img_size, img_size)\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1a5528",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5e95bb86b0738ec46e625ffe5f1157be",
     "grade": false,
     "grade_id": "cell-2d1152ac8504dae3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "tmp_generator = ConditionalGenerator(10, 1, 28, 100)\n",
    "tmp_noise = torch.randn(10, 100)\n",
    "tmp_labels = torch.randint(0, 10, (10,))\n",
    "tmp_img = tmp_generator(tmp_noise, tmp_labels)\n",
    "assert tmp_img.shape == (10, 1, 28, 28), \"Wrong shape of generated image\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3f45d9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "59f5ce9ce813247cd690bdcd2f84f25b",
     "grade": false,
     "grade_id": "cell-b36e1a6ce46967ff",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Here, we want you to implement the conditional discriminator. It should be a MLP with the follwing architecture:\n",
    "- An input node that takes the flattened image concatenated with the embedded label as input, and outputs 1024 nodes.\n",
    "- A LeakyReLU layer with a slope of 0.2.\n",
    "- 2 fully connected layers with 512 and 256 respectively, both followed by a Dropout layer with a probability of 0.4 and a LeakyReLU activation.\n",
    "- 1 fully connected layer with 128 nodes.\n",
    "- 1 output layer with 1 node follwed by a Sigmoid activation.\n",
    "\n",
    "The forward pass should:\n",
    "- Embed the label\n",
    "- Concatenate the image and the embedded label.\n",
    "- Pass the concatenated vector through the MLP.\n",
    "- Return the output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de355e18",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ba85bd59b1d6544a93041c2fff256855",
     "grade": true,
     "grade_id": "cell-dcd2f954d6f4e11c",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class ConditionalDiscriminator(nn.Module):\n",
    "    def __init__(self, n_classes: int, n_channels: int, img_size: int):\n",
    "        super(ConditionalDiscriminator, self).__init__()\n",
    "        self.n_classes = n_classes\n",
    "        self.n_channels = n_channels\n",
    "        self.img_size = img_size\n",
    "        self.img_shape = (self.n_channels, self.img_size, self.img_size)\n",
    "        self.label_embedding = nn.Embedding(self.n_classes, self.n_classes)\n",
    "        self.adv_loss = torch.nn.BCELoss()\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def forward(self, image: torch.Tensor, labels: torch.Tensor):\n",
    "        \"\"\"Classifies an image given a label.\n",
    "\n",
    "        Args:\n",
    "            image (torch.Tensor): An image of shape (batch_size, n_channels, img_size, img_size)\n",
    "            labels (torch.Tensor): A label vector of shape (batch_size)\n",
    "        Returns:\n",
    "            torch.Tensor: A classification score of shape (batch_size)\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        return self.model(x)\n",
    "\n",
    "    def loss(self, output, label):\n",
    "        return self.adv_loss(output, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0efdbd4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a172ee05fd965c0d6c0440a14a148453",
     "grade": false,
     "grade_id": "cell-c6018c2ab6bb3880",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "tmp_discriminator = ConditionalDiscriminator(10, 1, 28)\n",
    "tmp_img = torch.randn(10, 1, 28, 28)\n",
    "tmp_labels = torch.randint(0, 10, (10,))\n",
    "tmp_score = tmp_discriminator(tmp_img, tmp_labels)\n",
    "assert tmp_score.shape == (10, 1), \"Wrong shape of classification score\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7310f1b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d48515ace986112bcc526596b22f586d",
     "grade": false,
     "grade_id": "cell-53679a8e64fa4e95",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "To train the model, we have provided you with a training loop below. However, feel free to play around with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6455e964",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionalGan:\n",
    "    def __init__(\n",
    "        self,\n",
    "        device: str,\n",
    "        data_loader: torch.utils.data.DataLoader,\n",
    "        n_classes: int,\n",
    "        n_channels: int,\n",
    "        img_size: int,\n",
    "        latent_dim: int,\n",
    "    ):\n",
    "        self.device = device\n",
    "        self.data_loader = data_loader\n",
    "        self.n_classes = n_classes\n",
    "        self.n_channels = n_channels\n",
    "        self.img_size = img_size\n",
    "        self.latent_dim = latent_dim\n",
    "        self.generator = ConditionalGenerator(\n",
    "            self.n_classes, self.n_channels, self.img_size, self.latent_dim\n",
    "        )\n",
    "        self.generator.to(self.device)\n",
    "        self.discriminator = ConditionalDiscriminator(\n",
    "            self.n_classes, self.n_channels, self.img_size\n",
    "        )\n",
    "        self.discriminator.to(self.device)\n",
    "        self.optim_G = torch.optim.Adam(\n",
    "            filter(lambda p: p.requires_grad, self.generator.parameters()),\n",
    "            lr=1e-4,\n",
    "            betas=(0.5, 0.999),\n",
    "        )\n",
    "        self.optim_D = torch.optim.Adam(\n",
    "            filter(lambda p: p.requires_grad, self.discriminator.parameters()),\n",
    "            lr=1e-4,\n",
    "            betas=(0.5, 0.999),\n",
    "        )\n",
    "\n",
    "    def train(self, n_epochs: int, log_interval: int = 200):\n",
    "        self.generator.train()\n",
    "        self.discriminator.train()\n",
    "        viz_noise = torch.randn(10, self.latent_dim).to(self.device)\n",
    "        viz_labels = torch.arange(10).to(self.device)\n",
    "\n",
    "        for epoch in range(n_epochs):\n",
    "            batch_time = time.time()\n",
    "            for batch_idx, (data, target) in enumerate(self.data_loader):\n",
    "                data, target = data.to(self.device), target.to(self.device)\n",
    "                batch_size = data.size(0)\n",
    "                real_label = torch.full((batch_size, 1), 1.0, device=self.device)\n",
    "                fake_label = torch.full((batch_size, 1), 0.0, device=self.device)\n",
    "\n",
    "                # train generator\n",
    "                self.generator.zero_grad()\n",
    "                z_noise = torch.randn(batch_size, self.latent_dim, device=self.device)\n",
    "                x_fake_labels = torch.randint(\n",
    "                    0, self.n_classes, (batch_size,), device=self.device\n",
    "                )\n",
    "                x_fake = self.generator(z_noise, x_fake_labels)\n",
    "                y_fake_g = self.discriminator(x_fake, x_fake_labels)\n",
    "                g_loss = self.discriminator.loss(y_fake_g, real_label)\n",
    "                g_loss.backward()\n",
    "                self.optim_G.step()\n",
    "\n",
    "                # train discriminator\n",
    "                self.discriminator.zero_grad()\n",
    "                y_real = self.discriminator(data, target)\n",
    "                d_real_loss = self.discriminator.loss(y_real, real_label)\n",
    "                y_fake_d = self.discriminator(x_fake.detach(), x_fake_labels)\n",
    "                d_fake_loss = self.discriminator.loss(y_fake_d, fake_label)\n",
    "                d_loss = (d_real_loss + d_fake_loss) / 2\n",
    "                d_loss.backward()\n",
    "                self.optim_D.step()\n",
    "\n",
    "                if batch_idx % log_interval == 0 and batch_idx > 0:\n",
    "                    _, axs = plt.subplots(1, 10, figsize=(15, 15))\n",
    "                    with torch.no_grad():\n",
    "                        generated_images = self.generator(viz_noise, viz_labels)\n",
    "                    for i in range(10):\n",
    "                        axs[i].imshow(generated_images[i].squeeze(), cmap=\"gray\")\n",
    "                        axs[i].axis(\"off\")\n",
    "                    plt.show()\n",
    "\n",
    "                    print(\n",
    "                        \"Epoch {} [{}/{}] loss_D: {:.4f} loss_G: {:.4f} time: {:.2f}\".format(\n",
    "                            epoch,\n",
    "                            batch_idx,\n",
    "                            len(self.data_loader),\n",
    "                            d_loss.mean().item(),\n",
    "                            g_loss.mean().item(),\n",
    "                            time.time() - batch_time,\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "                    batch_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a5839c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e5837f07fdeec681b5b55c69d58d8e2d",
     "grade": false,
     "grade_id": "cell-50051cd127ac9dc7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Define the training. Feel free to experiment with both the architecture and the hyperparameters, however, the model should be able to generate images that look like the ones in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf17fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST_DATA_DIR = \"./mnist_data\"\n",
    "OUTPUT_DIR = \"./output\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "EPOCHS = 30\n",
    "IMG_SIZE = 32\n",
    "BATCH_SIZE = 128\n",
    "LATENT_DIM = 32\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device: {}\".format(DEVICE))\n",
    "\n",
    "print(\"Loading data...\\n\")\n",
    "dataset = dset.MNIST(\n",
    "    root=MNIST_DATA_DIR,\n",
    "    download=False,\n",
    "    transform=transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize(IMG_SIZE),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5,), (0.5,)),\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "assert dataset\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True\n",
    ")\n",
    "print(\"Creating model...\\n\")\n",
    "model = ConditionalGan(\n",
    "    device=DEVICE,\n",
    "    data_loader=dataloader,\n",
    "    n_classes=10,\n",
    "    n_channels=1,\n",
    "    img_size=IMG_SIZE,\n",
    "    latent_dim=LATENT_DIM,\n",
    ")\n",
    "\n",
    "# Train\n",
    "model.train(n_epochs=EPOCHS, log_interval=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9eef184",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f97c7835ac12b558974e7fbb0c166b14",
     "grade": false,
     "grade_id": "cell-527e75bb3ec2ee3d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now that we've trained the model, let's see how it performs. We can use the following function to generate images from the generator and see if they look similar to the ones in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72befb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# show some real data \n",
    "images, labels = next(iter(dataloader))\n",
    "images = images[:100]\n",
    "labels = labels[:100]\n",
    "fig, axs = plt.subplots(10, 10, figsize=(8, 8))\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        axs[i, j].imshow(images[i * 10 + j].squeeze(), cmap=\"gray\")\n",
    "        axs[i, j].axis(\"off\")\n",
    "plt.savefig(osp.join(OUTPUT_DIR, \"real_gridview.png\"))\n",
    "plt.show()\n",
    "\n",
    "# generate a 10x10 grid of images\n",
    "noise = torch.randn(100, model.latent_dim).to(DEVICE)\n",
    "with torch.no_grad():\n",
    "    generated_images = model.generator(noise, labels)\n",
    "\n",
    "fig, axs = plt.subplots(10, 10, figsize=(8, 8))\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        axs[i, j].imshow(generated_images[i * 10 + j].squeeze(), cmap=\"gray\")\n",
    "        axs[i, j].axis(\"off\")\n",
    "plt.savefig(osp.join(OUTPUT_DIR, \"fake_gridview.png\"))\n",
    "\n",
    "print(\"Can you tell the difference?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d57ca04",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "256217a766efeabc814d695aa6046907",
     "grade": false,
     "grade_id": "cell-db23ab995a5d9192",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Looking back\n",
    "Now that you've also implemented a conditional GAN, to be able to generate a particular sample from the data distrubution. As of now, you know absolutely everything there is to know about GANs, and therefore, it is time to look back at the previous assignment on VAEs. Here, we want you to contrast GANs to VAEs in the following aspects:\n",
    "1. What are they trained to do, respectively?\n",
    "2. Latent space: How are the latent spaces of GANs and VAEs different? \n",
    "3. Mode collapse: Are they equally prone to mode collapse? If not, which one is more prone?\n",
    "4. Applications: What are some applications of GANs and VAEs? What can you do with a VAE that is not suitable for a GAN?\n",
    "5. Quality of samples: Which one tends generate better data?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5915668",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b6037199ae08203529fef5f0983ad211",
     "grade": true,
     "grade_id": "cell-2c75e645cce187cc",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dgm",
   "language": "python",
   "name": "dgm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
